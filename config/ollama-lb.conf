# Ollama 72B Load Balancer Configuration
# Distributes requests across ROG Flow Z13 and Vengeance

upstream ollama_72b {
    # Least connections - routes to node with fewest active requests
    least_conn;

    # ROG Flow Z13 (Radeon 8060S + 64GB unified)
    # max_fails=2: mark as down after 2 failed requests
    # fail_timeout=30s: try again after 30 seconds
    server 100.93.122.109:11434 weight=1 max_fails=2 fail_timeout=30s;

    # Vengeance (RTX 4090 + 64GB DDR5)
    server 100.98.226.75:11434 weight=1 max_fails=2 fail_timeout=30s;

    # Keep connections alive for performance
    keepalive 4;
}

upstream ollama_local {
    # Local Ollama for non-72B models
    server 127.0.0.1:11434 max_fails=2 fail_timeout=30s;
    keepalive 2;
}

server {
    listen 11435;

    # Load balancer health check endpoint
    location /health {
        return 200 'OK';
        add_header Content-Type text/plain;
    }

    # Backend health status endpoint
    location /backends {
        default_type application/json;
        return 200 '{"backends":["100.93.122.109:11434","100.98.226.75:11434"],"strategy":"least_conn"}';
    }

    # Check individual backend health
    location /health/rog {
        proxy_pass http://100.93.122.109:11434/api/tags;
        proxy_connect_timeout 5s;
        proxy_read_timeout 5s;
    }

    location /health/vengeance {
        proxy_pass http://100.98.226.75:11434/api/tags;
        proxy_connect_timeout 5s;
        proxy_read_timeout 5s;
    }

    # 72B model endpoint - load balanced
    location /api/generate {
        proxy_pass http://ollama_72b;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_read_timeout 600s;
        proxy_send_timeout 600s;
        proxy_connect_timeout 10s;
        proxy_buffering off;

        # Retry on next upstream if connection fails
        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 2;
        proxy_next_upstream_timeout 30s;
    }

    # All other Ollama API endpoints
    location / {
        proxy_pass http://ollama_72b;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
        proxy_set_header Host $host;
        proxy_read_timeout 600s;
        proxy_send_timeout 600s;
        proxy_connect_timeout 10s;

        # Retry on next upstream if connection fails
        proxy_next_upstream error timeout http_502 http_503 http_504;
        proxy_next_upstream_tries 2;
        proxy_next_upstream_timeout 30s;
    }
}
